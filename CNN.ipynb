{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from keras import optimazier\n",
    "\n",
    "mnist=keras.datasets.mnist\n",
    "\n",
    "def get_train_val(mnist_path):\n",
    "    # mnist下载地址：https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data(mnist_path)\n",
    "    print(\"train_images nums:{}\".format(len(train_images)))\n",
    "    print(\"test_images nums:{}\".format(len(test_images)))\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def show_mnist(images,labels):\n",
    "     '''\n",
    "    将数据集可视化\n",
    "    '''\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([ ])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i],cmap=plt.cm.gray)\n",
    "        plt.xlabel(str(labels[i]))\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "独热码编码过程：\n",
    "\n",
    "　　假如只有一个特征是离散值：\n",
    "\n",
    "　　　　{sex：{male， female，other}}\n",
    "\n",
    "　　该特征总共有3个不同的分类值，此时需要3个bit位表示该特征是什么值，对应bit位为1的位置对应原来的特征的值（一般情况下可以将原始的特征的取值进行排序，以便于后期使用），此时得到独热码为{100}男性 ，{010}女性，{001}其他\n",
    "\n",
    "　　假如多个特征需要独热码编码，那么久按照上面的方法依次将每个特征的独热码拼接起来：\n",
    "\n",
    "　　　　{sex：{male， female，other}}\n",
    "\n",
    "　　　　{grade：{一年级， 二年级，三年级， 四年级}}\n",
    "\n",
    "　　此时对于输入为{sex：male； grade： 四年级}进行独热编码，可以首先将sex按照上面的进行编码得到{100}，然后按照grade进行编码为{0001}，那么两者连接起来得到最后的独热码{1000001}；\n",
    "'''\n",
    "def one_hot(labels):\n",
    "    onehot_labels=np.zeros(shape=[len(labels),10])\n",
    "    for i in range(len(labels)):\n",
    "        index=labels[i]\n",
    "        onehot_labels[i][index]=1\n",
    "    return onehot_labels\n",
    "\n",
    "def mnist_net(input_shape):\n",
    "    '''\n",
    "    构建一个简单的全连接层网络模型：\n",
    "    输入层为28x28=784个输入节点\n",
    "    隐藏层120个节点\n",
    "    输出层10个节点\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))           #输出层\n",
    "    model.add(keras.layers.Dense(units=100, activation=tf.nn.sigmoid)) #隐含层\n",
    "    model.add(keras.layers.Dense(units=10, activation=tf.nn.softmax))#输出层\n",
    "    return model\n",
    "\n",
    "def mnist_cnn2(input_shape):\n",
    "    '''\n",
    "    构建一个CNN网络模型\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "    model=keras.Sequential()\n",
    "    # 卷积层\n",
    "    model.add(keras.layers.Conv2D(filters=20,kernel_size = 5,strides = (1,1),\n",
    "                                  padding = 'same',activation = tf.nn.sigmoid,input_shape = input_shape))\n",
    "       # 最大化池化层\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters=40,kernel_size = 3,strides = (1,1),padding = 'same',activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "     # Dropout 层，正则化的一种方法，避免过拟合\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    # 把向量拉直，把二维变成一维\n",
    "    model.add(keras.layers.Flatten())\n",
    "    # 全连接层\n",
    "    model.add(keras.layers.Dense(units=100,activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units=10,activation = tf.nn.softmax))\n",
    "    return model\n",
    "def mnist_cnn(input_shape):\n",
    "    '''\n",
    "    构建一个CNN网络模型\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=20,kernel_size = 5,strides = (1,1),\n",
    "                                  padding = 'same',activation = tf.nn.sigmoid,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=100,activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units=10,activation = tf.nn.softmax))\n",
    "    return model\n",
    "def mnist_cnn2_2f(input_shape):\n",
    "    '''\n",
    "    构建一个CNN网络模型\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=20,kernel_size = 5,strides = (1,1),\n",
    "                                  padding = 'same',activation = tf.nn.relu,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters=40,kernel_size = 3,strides = (1,1),padding = 'same',activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=100,activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units=100,activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(units=10,activation = tf.nn.softmax))\n",
    "    return model\n",
    "def mnist_cnn2_2f_dropout(input_shape):\n",
    "    '''\n",
    "    构建一个CNN网络模型\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=20,kernel_size = 5,strides = (1,1),\n",
    "                                  padding = 'same',activation = tf.nn.relu,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters=40,kernel_size = 3,strides = (1,1),padding = 'same',activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=1000,activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=1000,activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=10,activation = tf.nn.softmax))\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    return model\n",
    "def mnist_cnn2_relu(input_shape):\n",
    "    '''\n",
    "    构建一个CNN网络模型\n",
    "    :param input_shape: 指定输入维度\n",
    "    :return:\n",
    "    '''\n",
    "    model=keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=20,kernel_size = 5,strides = (1,1),\n",
    "                                  padding = 'same',activation = tf.nn.relu,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters=40,kernel_size = 3,strides = (1,1),padding = 'same',activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=100,activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units=10,activation = tf.nn.softmax))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.5011 - acc: 0.8791\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2390 - acc: 0.9322\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1860 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1534 - acc: 0.9557\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1296 - acc: 0.9637\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1113 - acc: 0.9685\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0965 - acc: 0.9731\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0842 - acc: 0.9766\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0740 - acc: 0.9798\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0659 - acc: 0.9822\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.0918 - acc: 0.9717\n",
      "Test Accuracy 0.97\n",
      "correct prediction of total : 0.9717\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "    # 获取数据的标签\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    model = mnist_net(input_shape=(28,28,1))\n",
    "    # 将Adam优化器和损失函数连接起来\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    # 用模型拟合数据，即训练模型\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "    # 测试模型\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.2f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "# 主函数入口\n",
    "if __name__==\"__main__\":\n",
    "    # 读取数据\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # 可视化数据\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    # 训练模型\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 56s 938us/sample - loss: 1.2122 - acc: 0.6700\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.3224 - acc: 0.9172\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 58s 966us/sample - loss: 0.2060 - acc: 0.9438\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 58s 965us/sample - loss: 0.1496 - acc: 0.9586\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 58s 967us/sample - loss: 0.1146 - acc: 0.9686\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 58s 967us/sample - loss: 0.0943 - acc: 0.9731 - los\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 58s 974us/sample - loss: 0.0829 - acc: 0.9761\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 59s 976us/sample - loss: 0.0718 - acc: 0.9796\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.0655 - acc: 0.9807\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 59s 976us/sample - loss: 0.0588 - acc: 0.9826: 0s - loss: 0.0590\n",
      "10000/10000 [==============================] - 5s 483us/sample - loss: 0.0628 - acc: 0.9801\n",
      "Test Accuracy 0.98\n",
      "correct prediction of total : 0.9801\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    #model = mnist_net(input_shape=(28,28,1))\n",
    "    model=mnist_cnn(input_shape=(28,28,1))\n",
    "    #model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.4f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.8460 - acc: 0.7179\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.1593 - acc: 0.9539\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0926 - acc: 0.9735\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0681 - acc: 0.9808\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0533 - acc: 0.9844\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0377 - acc: 0.9888\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0238 - acc: 0.9930\n",
      "10000/10000 [==============================] - 6s 592us/sample - loss: 0.0364 - acc: 0.9882\n",
      "Test Accuracy 0.9882\n",
      "correct prediction of total : 0.9882\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    #model = mnist_net(input_shape=(28,28,1))\n",
    "    model=mnist_cnn2(input_shape=(28,28,1))\n",
    "    #model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.4f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.1781 - acc: 0.9463\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0517 - acc: 0.9841\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0369 - acc: 0.9890\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0281 - acc: 0.9913\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0230 - acc: 0.9927\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0173 - acc: 0.9942\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0133 - acc: 0.9957\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.0119 - acc: 0.9960\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0090 - acc: 0.9970\n",
      "10000/10000 [==============================] - 6s 564us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Test Accuracy 0.9917\n",
      "correct prediction of total : 0.9917\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    #model = mnist_net(input_shape=(28,28,1))\n",
    "    model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    #model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.4f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.1696 - acc: 0.9492\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0498 - acc: 0.9846\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0341 - acc: 0.9892\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0273 - acc: 0.9911\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0196 - acc: 0.9935 0s - loss: 0.0198 - \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0175 - acc: 0.9940\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0128 - acc: 0.99601s - loss:\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0117 - acc: 0.99635s - l\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0092 - acc: 0.9971\n",
      "10000/10000 [==============================] - 6s 554us/sample - loss: 0.0285 - acc: 0.9914\n",
      "Test Accuracy 0.9914\n",
      "correct prediction of total : 0.9914\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    #model = mnist_net(input_shape=(28,28,1))\n",
    "    model=mnist_cnn2_relu(input_shape=(28,28,1))\n",
    "    #model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.4f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.1652 - acc: 0.9483\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0544 - acc: 0.9835\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0397 - acc: 0.9881\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0352 - acc: 0.9896\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0296 - acc: 0.9912\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0215 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0208 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0183 - acc: 0.9947\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0184 - acc: 0.9947\n",
      "10000/10000 [==============================] - 6s 600us/sample - loss: 0.0355 - acc: 0.9914\n",
      "Test Accuracy 0.9914\n",
      "correct prediction of total : 0.9914\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images,train_labels,test_images,test_labels):\n",
    "    # re-scale to 0~1.0之间\n",
    "    train_images=train_images/255.0\n",
    "    test_images=test_images/255.0\n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立模型\n",
    "    #model = mnist_net(input_shape=(28,28,1))\n",
    "    model=mnist_cnn2_2f_dropout(input_shape=(28,28,1))\n",
    "    #model=mnist_cnn2_2f(input_shape=(28,28,1))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    model.fit(x=train_images,y=train_labels,epochs=10,batch_size=64)\n",
    "\n",
    "    test_loss,test_acc=model.evaluate(x=test_images,y=test_labels)\n",
    "    print(\"Test Accuracy %.4f\"%test_acc)\n",
    "\n",
    "    # 开始预测\n",
    "    cnt=0\n",
    "    predictions=model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target=np.argmax(predictions[i])\n",
    "        label=np.argmax(test_labels[i])\n",
    "        if target==label:\n",
    "            cnt +=1\n",
    "    print(\"correct prediction of total : %.4f\"%(cnt/len(test_images)))\n",
    "\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    mnist_path = 'D:/research_object_detect/temp/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels=get_train_val(mnist_path)\n",
    "    # show_mnist(train_images, train_labels)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
